{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed torch-1.12.0 torchtext-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install \"torch>=1.12\" \"torchtext>=0.13\" transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 420M/420M [00:04<00:00, 102MB/s]  \n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload=\"Hello World, How are you!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  7592,  2088,  1010,  2129,  2024,  2017,   999,   102,     0,\n",
       "             0,     0,     0,     0],\n",
       "        [  101,  2023,  2003,  1037,  2936,  5537,  2000,  2156,  2065, 11687,\n",
       "          4667,  2052,  2147,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "trfs_tok = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "trfs_ex = trfs_tok([payload,\"this is a longer sequence to see if padding would work\"],padding=True,return_tensors=\"pt\")\n",
    "model(**trfs_ex)\n",
    "trfs_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 µs ± 938 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "trfs_ex = trfs_tok(payload,\"this is a longer sequence to see if padding would work\",padding=True,return_tensors=\"pt\")\n",
    "trfs_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 35378, 6661, 4, 11249, 621, 398, 38, 2]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchtext.transforms as T\n",
    "from torch.hub import load_state_dict_from_url\n",
    "\n",
    "padding_idx = 1\n",
    "bos_idx = 0\n",
    "eos_idx = 2\n",
    "max_seq_len = 256\n",
    "xlmr_vocab_path = r\"https://download.pytorch.org/models/text/xlmr.vocab.pt\"\n",
    "xlmr_spm_model_path = r\"https://download.pytorch.org/models/text/xlmr.sentencepiece.bpe.model\"\n",
    "\n",
    "text_transform = T.Sequential(\n",
    "    T.SentencePieceTokenizer(xlmr_spm_model_path),\n",
    "    T.VocabTransform(load_state_dict_from_url(xlmr_vocab_path)),\n",
    "    T.Truncate(max_seq_len - 2),\n",
    "    T.AddToken(token=bos_idx, begin=True),\n",
    "    T.AddToken(token=eos_idx, begin=False),\n",
    ")\n",
    "text_transform(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.transforms import BERTTokenizer\n",
    "VOCAB_FILE = \"https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt\"\n",
    "tokenizer = BERTTokenizer(vocab_path=VOCAB_FILE, do_lower_case=True, return_tokens=False)\n",
    "pt_ex = tokenizer(\"Hello World, How are you!\") # single sentence input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  7592,  2088,  1010,  2129,  2024,  2017,   999,   102,     0,\n",
       "             0,     0,     0,     0],\n",
       "        [  101,  2023,  2003,  1037,  2936,  5537,  2000,  2156,  2065, 11687,\n",
       "          4667,  2052,  2147,   102]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len=512\n",
    "bos_idx=101\n",
    "eos_idx=102\n",
    "padding_value=0\n",
    "tokenizer = T.Sequential(\n",
    "    T.BERTTokenizer(vocab_path=VOCAB_FILE, do_lower_case=True, return_tokens=False),\n",
    "    T.StrToIntTransform(),\n",
    "    T.Truncate(max_seq_len - 2),\n",
    "    T.AddToken(token=bos_idx, begin=True),\n",
    "    T.AddToken(token=eos_idx, begin=False),\n",
    "    T.ToTensor(padding_value=padding_value)\n",
    ")\n",
    "tokenizer([payload,\"this is a longer sequence to see if padding would work\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids= tokenizer([payload,\"this is a longer sequence to see if padding would work\"])\n",
    "val = input_ids,input_ids.gt(0).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "  pt_res = model(*val)\n",
    "  trfs_res = model(**trfs_ex)\n",
    "\n",
    "assert pt_res.last_hidden_state.shape == trfs_res.last_hidden_state.shape\n",
    "assert torch.allclose(pt_res.last_hidden_state,trfs_res.last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from typing import Any, List, Optional, Union,Dict\n",
    "\n",
    "class PTBertTokenizer(nn.Module):\n",
    "  def __init__(self,vocab_file_path=None,do_lower_case=True,bos_idx=101,eos_idx=102,padding_value=0):\n",
    "    super().__init__()\n",
    "    self.tokenizer=T.Sequential(\n",
    "      T.BERTTokenizer(vocab_path=vocab_file_path, do_lower_case=do_lower_case, return_tokens=False),\n",
    "      T.StrToIntTransform(),\n",
    "      T.Truncate(max_seq_len - 2),\n",
    "      T.AddToken(token=bos_idx, begin=True),\n",
    "      T.AddToken(token=eos_idx, begin=False),\n",
    "      T.ToTensor(padding_value=padding_value)\n",
    "  )\n",
    "\n",
    "  def forward(self,input:Union[str,List[str]])->Dict[str,torch.Tensor]:\n",
    "    input_ids = self.tokenizer(input)\n",
    "    # shape tensor to matching format for transformers model\n",
    "    input_ids = torch.reshape(input_ids, (1,input_ids.shape[-1]))\n",
    "    return {'input_ids':input_ids,\"attention_mask\":input_ids.gt(0).to(torch.int64)}\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\nModule 'BERTTokenizer' has no attribute 'bert_model' (This attribute exists on the Python module, but we failed to convert Python type: 'torchtext._torchtext.BERTEncoder' to a TorchScript type. Only tensors and (possibly nested) tuples of tensors, lists, or dictsare supported as inputs or outputs of traced functions, but instead got value of type BERTEncoder.. Its type was inferred; try adding a type annotation for the attribute.):\n  File \"/home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torchtext/transforms.py\", line 603\n    def _batch_encode(self, text: List[str]) -> List[List[str]]:\n        \"\"\"Batch version of _encode i.e operate on list of str\"\"\"\n        token_ids: List[List[int]] = self.bert_model.batch_encode([t.strip() for t in text])\n                                     ~~~~~~~~~~~~~~~ <--- HERE\n        tokens_ids_str: List[List[str]] = [[str(t) for t in token_id] for token_id in token_ids]\n        return tokens_ids_str\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/pytorch-bert-e2e-model/notebook.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Binfinity-gpu/home/ubuntu/pytorch-bert-e2e-model/notebook.ipynb#ch0000024vscode-remote?line=0'>1</a>\u001b[0m traced_tokenizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mtrace(pt_tokenizer, \u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py:750\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=746'>747</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m func\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=748'>749</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(func, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[0;32m--> <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=749'>750</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m trace_module(\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=750'>751</a>\u001b[0m         func,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=751'>752</a>\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mforward\u001b[39;49m\u001b[39m\"\u001b[39;49m: example_inputs},\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=752'>753</a>\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=753'>754</a>\u001b[0m         check_trace,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=754'>755</a>\u001b[0m         wrap_check_inputs(check_inputs),\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=755'>756</a>\u001b[0m         check_tolerance,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=756'>757</a>\u001b[0m         strict,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=757'>758</a>\u001b[0m         _force_outplace,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=758'>759</a>\u001b[0m         _module_class,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=759'>760</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=761'>762</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=762'>763</a>\u001b[0m     \u001b[39mhasattr\u001b[39m(func, \u001b[39m\"\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=763'>764</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(func\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule)\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=764'>765</a>\u001b[0m     \u001b[39mand\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=765'>766</a>\u001b[0m ):\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=766'>767</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m trace_module(\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=767'>768</a>\u001b[0m         func\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=768'>769</a>\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m: example_inputs},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=775'>776</a>\u001b[0m         _module_class,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=776'>777</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py:951\u001b[0m, in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=947'>948</a>\u001b[0m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_trace\u001b[39m.\u001b[39m_trace_module_map \u001b[39m=\u001b[39m trace_module_map\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=948'>949</a>\u001b[0m register_submods(mod, \u001b[39m\"\u001b[39m\u001b[39m__module\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=950'>951</a>\u001b[0m module \u001b[39m=\u001b[39m make_module(mod, _module_class, _compilation_unit)\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=952'>953</a>\u001b[0m \u001b[39mfor\u001b[39;00m method_name, example_inputs \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=953'>954</a>\u001b[0m     \u001b[39mif\u001b[39;00m method_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=954'>955</a>\u001b[0m         \u001b[39m# \"forward\" is a special case because we need to trace\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=955'>956</a>\u001b[0m         \u001b[39m# `Module.__call__`, which sets up some extra tracing, but uses\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=956'>957</a>\u001b[0m         \u001b[39m# argument names of the real `Module.forward` method.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py:577\u001b[0m, in \u001b[0;36mmake_module\u001b[0;34m(mod, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=574'>575</a>\u001b[0m \u001b[39mif\u001b[39;00m _module_class \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=575'>576</a>\u001b[0m     _module_class \u001b[39m=\u001b[39m TopLevelTracedModule\n\u001b[0;32m--> <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=576'>577</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _module_class(mod, _compilation_unit\u001b[39m=\u001b[39;49m_compilation_unit)\n",
      "File \u001b[0;32m~/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py:1076\u001b[0m, in \u001b[0;36mTracedModule.__init__\u001b[0;34m(self, orig, id_set, _compilation_unit)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=1073'>1074</a>\u001b[0m     \u001b[39mif\u001b[39;00m submodule \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=1074'>1075</a>\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=1075'>1076</a>\u001b[0m     tmp_module\u001b[39m.\u001b[39m_modules[name] \u001b[39m=\u001b[39m make_module(\n\u001b[1;32m   <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=1076'>1077</a>\u001b[0m         submodule, TracedModule, _compilation_unit\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=1077'>1078</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=1079'>1080</a>\u001b[0m script_module \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_recursive\u001b[39m.\u001b[39mcreate_script_module(\n\u001b[1;32m   <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=1080'>1081</a>\u001b[0m     tmp_module, \u001b[39mlambda\u001b[39;00m module: (), share_types\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, is_tracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=1081'>1082</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=1083'>1084</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39m_name\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(orig)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py:577\u001b[0m, in \u001b[0;36mmake_module\u001b[0;34m(mod, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=574'>575</a>\u001b[0m \u001b[39mif\u001b[39;00m _module_class \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=575'>576</a>\u001b[0m     _module_class \u001b[39m=\u001b[39m TopLevelTracedModule\n\u001b[0;32m--> <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=576'>577</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _module_class(mod, _compilation_unit\u001b[39m=\u001b[39;49m_compilation_unit)\n",
      "File \u001b[0;32m~/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py:1076\u001b[0m, in \u001b[0;36mTracedModule.__init__\u001b[0;34m(self, orig, id_set, _compilation_unit)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=1073'>1074</a>\u001b[0m     \u001b[39mif\u001b[39;00m submodule \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=1074'>1075</a>\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=1075'>1076</a>\u001b[0m     tmp_module\u001b[39m.\u001b[39m_modules[name] \u001b[39m=\u001b[39m make_module(\n\u001b[1;32m   <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=1076'>1077</a>\u001b[0m         submodule, TracedModule, _compilation_unit\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=1077'>1078</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=1079'>1080</a>\u001b[0m script_module \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_recursive\u001b[39m.\u001b[39mcreate_script_module(\n\u001b[1;32m   <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=1080'>1081</a>\u001b[0m     tmp_module, \u001b[39mlambda\u001b[39;00m module: (), share_types\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, is_tracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=1081'>1082</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=1083'>1084</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39m_name\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(orig)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py:568\u001b[0m, in \u001b[0;36mmake_module\u001b[0;34m(mod, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=564'>565</a>\u001b[0m \u001b[39melif\u001b[39;00m torch\u001b[39m.\u001b[39m_jit_internal\u001b[39m.\u001b[39mmodule_has_exports(mod):\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=566'>567</a>\u001b[0m     infer_methods_stubs_fn \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_recursive\u001b[39m.\u001b[39mmake_stubs_from_exported_methods\n\u001b[0;32m--> <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=567'>568</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49m_recursive\u001b[39m.\u001b[39;49mcreate_script_module(\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=568'>569</a>\u001b[0m         mod,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=569'>570</a>\u001b[0m         infer_methods_stubs_fn,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=570'>571</a>\u001b[0m         share_types\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=571'>572</a>\u001b[0m         is_tracing\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=572'>573</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=573'>574</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=574'>575</a>\u001b[0m     \u001b[39mif\u001b[39;00m _module_class \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py:458\u001b[0m, in \u001b[0;36mcreate_script_module\u001b[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=455'>456</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tracing:\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=456'>457</a>\u001b[0m     AttributeTypeIsSupportedChecker()\u001b[39m.\u001b[39mcheck(nn_module)\n\u001b[0;32m--> <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=457'>458</a>\u001b[0m \u001b[39mreturn\u001b[39;00m create_script_module_impl(nn_module, concrete_type, stubs_fn)\n",
      "File \u001b[0;32m~/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py:524\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=521'>522</a>\u001b[0m \u001b[39m# Compile methods if necessary\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=522'>523</a>\u001b[0m \u001b[39mif\u001b[39;00m concrete_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m concrete_type_store\u001b[39m.\u001b[39mmethods_compiled:\n\u001b[0;32m--> <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=523'>524</a>\u001b[0m     create_methods_and_properties_from_stubs(concrete_type, method_stubs, property_stubs)\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=524'>525</a>\u001b[0m     \u001b[39m# Create hooks after methods to ensure no name collisions between hooks and methods.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=525'>526</a>\u001b[0m     \u001b[39m# If done before, hooks can overshadow methods that aren't exported.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=526'>527</a>\u001b[0m     create_hooks_from_stubs(concrete_type, hook_stubs, pre_hook_stubs)\n",
      "File \u001b[0;32m~/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py:375\u001b[0m, in \u001b[0;36mcreate_methods_and_properties_from_stubs\u001b[0;34m(concrete_type, method_stubs, property_stubs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=371'>372</a>\u001b[0m property_defs \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mdef_ \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m property_stubs]\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=372'>373</a>\u001b[0m property_rcbs \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mresolution_callback \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m property_stubs]\n\u001b[0;32m--> <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=374'>375</a>\u001b[0m concrete_type\u001b[39m.\u001b[39;49m_create_methods_and_properties(property_defs, property_rcbs, method_defs, method_rcbs, method_defaults)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \nModule 'BERTTokenizer' has no attribute 'bert_model' (This attribute exists on the Python module, but we failed to convert Python type: 'torchtext._torchtext.BERTEncoder' to a TorchScript type. Only tensors and (possibly nested) tuples of tensors, lists, or dictsare supported as inputs or outputs of traced functions, but instead got value of type BERTEncoder.. Its type was inferred; try adding a type annotation for the attribute.):\n  File \"/home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torchtext/transforms.py\", line 603\n    def _batch_encode(self, text: List[str]) -> List[List[str]]:\n        \"\"\"Batch version of _encode i.e operate on list of str\"\"\"\n        token_ids: List[List[int]] = self.bert_model.batch_encode([t.strip() for t in text])\n                                     ~~~~~~~~~~~~~~~ <--- HERE\n        tokens_ids_str: List[List[str]] = [[str(t) for t in token_id] for token_id in token_ids]\n        return tokens_ids_str\n"
     ]
    }
   ],
   "source": [
    "traced_tokenizer = torch.jit.trace(pt_tokenizer, \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\nModule 'BERTTokenizer' has no attribute 'bert_model' (This attribute exists on the Python module, but we failed to convert Python type: 'torchtext._torchtext.BERTEncoder' to a TorchScript type. Only tensors and (possibly nested) tuples of tensors, lists, or dictsare supported as inputs or outputs of traced functions, but instead got value of type BERTEncoder.. Its type was inferred; try adding a type annotation for the attribute.):\n  File \"/home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torchtext/transforms.py\", line 603\n    def _batch_encode(self, text: List[str]) -> List[List[str]]:\n        \"\"\"Batch version of _encode i.e operate on list of str\"\"\"\n        token_ids: List[List[int]] = self.bert_model.batch_encode([t.strip() for t in text])\n                                     ~~~~~~~~~~~~~~~ <--- HERE\n        tokens_ids_str: List[List[str]] = [[str(t) for t in token_id] for token_id in token_ids]\n        return tokens_ids_str\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/pytorch-bert-e2e-model/notebook.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Binfinity-gpu/home/ubuntu/pytorch-bert-e2e-model/notebook.ipynb#ch0000025vscode-remote?line=3'>4</a>\u001b[0m \u001b[39m# Instantiate tokenizer with lower case, and return tokens=True (we also support return token IDs instead)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Binfinity-gpu/home/ubuntu/pytorch-bert-e2e-model/notebook.ipynb#ch0000025vscode-remote?line=4'>5</a>\u001b[0m bert_tokenizer \u001b[39m=\u001b[39m T\u001b[39m.\u001b[39mBERTTokenizer(get_asset_local_path(bert_base_uncased_vocab_file),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Binfinity-gpu/home/ubuntu/pytorch-bert-e2e-model/notebook.ipynb#ch0000025vscode-remote?line=5'>6</a>\u001b[0m                                     do_lower_case\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, strip_accents\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, return_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Binfinity-gpu/home/ubuntu/pytorch-bert-e2e-model/notebook.ipynb#ch0000025vscode-remote?line=7'>8</a>\u001b[0m traced_tokenizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mtrace(bert_tokenizer, \u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py:750\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=746'>747</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m func\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=748'>749</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(func, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[0;32m--> <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=749'>750</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m trace_module(\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=750'>751</a>\u001b[0m         func,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=751'>752</a>\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mforward\u001b[39;49m\u001b[39m\"\u001b[39;49m: example_inputs},\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=752'>753</a>\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=753'>754</a>\u001b[0m         check_trace,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=754'>755</a>\u001b[0m         wrap_check_inputs(check_inputs),\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=755'>756</a>\u001b[0m         check_tolerance,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=756'>757</a>\u001b[0m         strict,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=757'>758</a>\u001b[0m         _force_outplace,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=758'>759</a>\u001b[0m         _module_class,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=759'>760</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=761'>762</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=762'>763</a>\u001b[0m     \u001b[39mhasattr\u001b[39m(func, \u001b[39m\"\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=763'>764</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(func\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule)\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=764'>765</a>\u001b[0m     \u001b[39mand\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=765'>766</a>\u001b[0m ):\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=766'>767</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m trace_module(\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=767'>768</a>\u001b[0m         func\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=768'>769</a>\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m: example_inputs},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=775'>776</a>\u001b[0m         _module_class,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=776'>777</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py:951\u001b[0m, in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=947'>948</a>\u001b[0m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_trace\u001b[39m.\u001b[39m_trace_module_map \u001b[39m=\u001b[39m trace_module_map\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=948'>949</a>\u001b[0m register_submods(mod, \u001b[39m\"\u001b[39m\u001b[39m__module\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=950'>951</a>\u001b[0m module \u001b[39m=\u001b[39m make_module(mod, _module_class, _compilation_unit)\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=952'>953</a>\u001b[0m \u001b[39mfor\u001b[39;00m method_name, example_inputs \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=953'>954</a>\u001b[0m     \u001b[39mif\u001b[39;00m method_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=954'>955</a>\u001b[0m         \u001b[39m# \"forward\" is a special case because we need to trace\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=955'>956</a>\u001b[0m         \u001b[39m# `Module.__call__`, which sets up some extra tracing, but uses\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=956'>957</a>\u001b[0m         \u001b[39m# argument names of the real `Module.forward` method.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py:568\u001b[0m, in \u001b[0;36mmake_module\u001b[0;34m(mod, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=564'>565</a>\u001b[0m \u001b[39melif\u001b[39;00m torch\u001b[39m.\u001b[39m_jit_internal\u001b[39m.\u001b[39mmodule_has_exports(mod):\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=566'>567</a>\u001b[0m     infer_methods_stubs_fn \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_recursive\u001b[39m.\u001b[39mmake_stubs_from_exported_methods\n\u001b[0;32m--> <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=567'>568</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49m_recursive\u001b[39m.\u001b[39;49mcreate_script_module(\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=568'>569</a>\u001b[0m         mod,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=569'>570</a>\u001b[0m         infer_methods_stubs_fn,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=570'>571</a>\u001b[0m         share_types\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=571'>572</a>\u001b[0m         is_tracing\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=572'>573</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=573'>574</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_trace.py?line=574'>575</a>\u001b[0m     \u001b[39mif\u001b[39;00m _module_class \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py:458\u001b[0m, in \u001b[0;36mcreate_script_module\u001b[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=455'>456</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tracing:\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=456'>457</a>\u001b[0m     AttributeTypeIsSupportedChecker()\u001b[39m.\u001b[39mcheck(nn_module)\n\u001b[0;32m--> <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=457'>458</a>\u001b[0m \u001b[39mreturn\u001b[39;00m create_script_module_impl(nn_module, concrete_type, stubs_fn)\n",
      "File \u001b[0;32m~/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py:524\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=521'>522</a>\u001b[0m \u001b[39m# Compile methods if necessary\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=522'>523</a>\u001b[0m \u001b[39mif\u001b[39;00m concrete_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m concrete_type_store\u001b[39m.\u001b[39mmethods_compiled:\n\u001b[0;32m--> <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=523'>524</a>\u001b[0m     create_methods_and_properties_from_stubs(concrete_type, method_stubs, property_stubs)\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=524'>525</a>\u001b[0m     \u001b[39m# Create hooks after methods to ensure no name collisions between hooks and methods.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=525'>526</a>\u001b[0m     \u001b[39m# If done before, hooks can overshadow methods that aren't exported.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=526'>527</a>\u001b[0m     create_hooks_from_stubs(concrete_type, hook_stubs, pre_hook_stubs)\n",
      "File \u001b[0;32m~/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py:375\u001b[0m, in \u001b[0;36mcreate_methods_and_properties_from_stubs\u001b[0;34m(concrete_type, method_stubs, property_stubs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=371'>372</a>\u001b[0m property_defs \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mdef_ \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m property_stubs]\n\u001b[1;32m    <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=372'>373</a>\u001b[0m property_rcbs \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mresolution_callback \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m property_stubs]\n\u001b[0;32m--> <a href='file:///home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torch/jit/_recursive.py?line=374'>375</a>\u001b[0m concrete_type\u001b[39m.\u001b[39;49m_create_methods_and_properties(property_defs, property_rcbs, method_defs, method_rcbs, method_defaults)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \nModule 'BERTTokenizer' has no attribute 'bert_model' (This attribute exists on the Python module, but we failed to convert Python type: 'torchtext._torchtext.BERTEncoder' to a TorchScript type. Only tensors and (possibly nested) tuples of tensors, lists, or dictsare supported as inputs or outputs of traced functions, but instead got value of type BERTEncoder.. Its type was inferred; try adding a type annotation for the attribute.):\n  File \"/home/ubuntu/miniconda3/envs/optimum/lib/python3.8/site-packages/torchtext/transforms.py\", line 603\n    def _batch_encode(self, text: List[str]) -> List[List[str]]:\n        \"\"\"Batch version of _encode i.e operate on list of str\"\"\"\n        token_ids: List[List[int]] = self.bert_model.batch_encode([t.strip() for t in text])\n                                     ~~~~~~~~~~~~~~~ <--- HERE\n        tokens_ids_str: List[List[str]] = [[str(t) for t in token_id] for token_id in token_ids]\n        return tokens_ids_str\n"
     ]
    }
   ],
   "source": [
    "bert_base_uncased_vocab_file = \"https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt\"\n",
    "import torchtext.transforms as T\n",
    "from torchtext.utils import get_asset_local_path\n",
    "# Instantiate tokenizer with lower case, and return tokens=True (we also support return token IDs instead)\n",
    "bert_tokenizer = T.BERTTokenizer(get_asset_local_path(bert_base_uncased_vocab_file),\n",
    "                                    do_lower_case=True, strip_accents=None, return_tokens=True)\n",
    "\n",
    "traced_tokenizer = torch.jit.trace(bert_tokenizer, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E2e Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from typing import Any, List, Optional, Union,Dict\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import torchtext.transforms as T\n",
    "\n",
    "VOCAB_FILE=\"https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt\"\n",
    "\n",
    "class E2EModel(nn.Module):\n",
    "  def __init__(self,model_id=None):\n",
    "    super().__init__()\n",
    "    self.tokenizer=PTBertTokenizer(VOCAB_FILE)\n",
    "    self.model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "\n",
    "  def forward(self,inputs:Union[str,List[str]]) -> Dict[str,torch.Tensor]:\n",
    "      tokenized = self.tokenizer(inputs)\n",
    "      print(tokenized)\n",
    "      return self.model(**tokenized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1045, 2066, 2017,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-4.2960,  4.6485]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = E2EModel(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "pipe(\"I like you\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E2E Classification pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998695850372314}, {'label': 'NEGATIVE', 'score': 0.9991033673286438}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998695850372314}]\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Union, Dict, Any\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchtext import transforms as T\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "class PTBertTokenizer(nn.Module):\n",
    "  def __init__(self,vocab_file_path=None,do_lower_case=True,bos_idx=101,eos_idx=102,padding_value=0,max_seq_len=512):\n",
    "    super().__init__()\n",
    "    self.tokenizer=T.Sequential(\n",
    "      T.BERTTokenizer(vocab_path=vocab_file_path, do_lower_case=do_lower_case, return_tokens=False),\n",
    "      T.StrToIntTransform(),\n",
    "      T.Truncate(max_seq_len - 2),\n",
    "      T.AddToken(token=bos_idx, begin=True),\n",
    "      T.AddToken(token=eos_idx, begin=False),\n",
    "      T.ToTensor(padding_value=padding_value)\n",
    "  )\n",
    "\n",
    "  def forward(self,input:Union[str,List[str]])->Dict[str,torch.Tensor]:\n",
    "    input_ids = self.tokenizer(input)\n",
    "    # shape tensor to matching format for transformers model\n",
    "    if input_ids.dim() == 1:\n",
    "      input_ids = torch.reshape(input_ids, (1,input_ids.shape[-1]))\n",
    "    return {'input_ids':input_ids,\"attention_mask\":input_ids.gt(0).to(torch.int64)}\n",
    "\n",
    "  @classmethod\n",
    "  def from_pretrained(cls, model_id: str):\n",
    "    remote_file=f\"https://huggingface.co/{model_id}/resolve/main/vocab.txt\"\n",
    "    return cls(vocab_file_path=remote_file)\n",
    "\n",
    "\n",
    "class E2ETextClassification(nn.Module):\n",
    "  def __init__(self,model_id=None):\n",
    "    super().__init__()\n",
    "    self.tokenizer=PTBertTokenizer.from_pretrained(model_id)\n",
    "    self.model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "\n",
    "  def forward(self,inputs:Union[str,List[str]]) -> List[Dict[str,Any]]:\n",
    "      # preprocessing\n",
    "      tokenized = self.tokenizer(inputs)\n",
    "      with torch.no_grad():\n",
    "        logits = self.model(**tokenized).logits\n",
    "        scores=nn.Softmax(dim=-1)(logits)\n",
    "      # post processing\n",
    "      return [{\"label\": self.model.config.id2label[score.argmax().item()], \"score\": score.max().item()} for score in scores]\n",
    "\n",
    "pipe = E2ETextClassification(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "scores = pipe([\"I like you\",\"i hate you very much\"])\n",
    "print(scores)\n",
    "scores = pipe(\"I like you\")\n",
    "print(scores)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pipe, \"pipe.pt\")\n",
    "loaded_pipe=torch.load(\"pipe.pt\")\n",
    "loaded_pipe(\"it is so awesome that i can load and save the whole pipeline\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998151659965515}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f36b26331983026f8e17055c9ec364356a568fdb88f981272e009cb090adf63f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('optimum')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
